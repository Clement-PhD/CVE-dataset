# update the data getting the parent commit of each merged pull request in the master or main branch
import argparse
from dataclasses import dataclass
import json
import os
from dotenv import load_dotenv, find_dotenv
from download.github_request import GithubRequests
from tqdm import tqdm

load_dotenv(override=True)

#PULL_REQUEST_URL = "https://github.com/memcached/memcached/pull/806"
#CVE = "CVE-2021-37519"

DATA_FOLDER = "data/"

@dataclass
class CommitInfos:
    merged_commit_sha: str
    parents_commit_sha: list[str]

    def to_serializable(self):
        return {"merged_commit_sha": self.merged_commit_sha, "parents_commit_sha": self.parents_commit_sha}



def get_argv_parser():
    parser = argparse.ArgumentParser(description='update the data getting the parent commit of each merged pull request in the master or main branch')
    parser.add_argument('--clean', action='store_true', help="Remove the files if it exists")
    # dry run
    parser.add_argument('--dry_run', action='store_true', help="Do not save the data")
    return parser

if __name__ == "__main__":
    parser = get_argv_parser()
    args = parser.parse_args()

    github_requests = GithubRequests()

    commit_done_nb = 0
    commit_failed_nb = 0

    # iterate on all the folder in the data folder
    # for each folder, get the merged pull request
    all_folder = os.listdir(DATA_FOLDER)
    all_folder.sort()

    # remove all old commit_infos.json
    if args.clean:
        print("Cleaning all commit_infos.json")
        for folder in all_folder:
            file_path = DATA_FOLDER + folder + "/commit_infos.json"
            if os.path.exists(file_path):
                os.remove(file_path)

    bar = tqdm(all_folder)    
    for folder in bar:
        if os.path.isdir(DATA_FOLDER + folder):
            bar.set_description(f"Processing {folder}")
            pull_request_json_path = DATA_FOLDER + folder + "/data.json"
            file_path = DATA_FOLDER + folder + "/commit_infos.json"
            if os.path.exists(file_path):
                commit_done_nb += 1
                continue

            url : str
            if os.path.exists(pull_request_json_path):
                with open(pull_request_json_path, "r") as f:
                    data = json.load(f)
                   
                    # get the url
                    if "_links" in data:
                        if "commits" in data["_links"]:
                            if "href" in data["_links"]["commits"]:
                                url = data["_links"]["commits"]["href"]
                            else:
                                print(f"no href in commits in {pull_request_json_path}")
                                exit(1)
                        else:
                            print(f"no commits in _links in {pull_request_json_path}")
                            exit(1)
                    else:
                        print(f"no _links in {pull_request_json_path}")
                        exit(1)
            else:
                print(f"file {pull_request_json_path} does not exist")
                exit(1)
            
            # get the parent commit of the merged commit using github api
            
            # remove the starting 
            url = url.replace(GithubRequests.BASE_API_URL, "")
            # get the commit data
            commit_data = github_requests.get(url)
            if commit_data is None:
                tqdm.write(f"Failed to get data from {url}")
                commit_failed_nb += 1
                continue

            # commit_data is a list of commit, so get the last one
            if len(commit_data) == 0:
                tqdm.write(f"no commit in {GithubRequests.BASE_API_URL + url}")
                commit_failed_nb += 1
                continue
            commit_data = commit_data[-1]

            # get the parent commit
            parent_commit = list()
            if "parents" in commit_data:
                for parent in commit_data["parents"]:
                    if "sha" in parent:
                        parent_commit.append(parent["sha"])
                    else:
                        print(f"no sha in parent in {GithubRequests.BASE_API_URL + url}")
                        exit(1)
            else:
                print(f"no parent in {GithubRequests.BASE_API_URL + url}")
                exit(1)
            # get the merged commit
            merged_commit = commit_data["sha"]
            
            # save the data
            commit_infos = CommitInfos(merged_commit, parent_commit)
            if not args.dry_run:
          
                with open(file_path, "w") as f:
                    json.dump(commit_infos.to_serializable(), f, indent=4)
            
            commit_done_nb += 1
    
    print(f"Done: {commit_done_nb} done, {commit_failed_nb} failed")
            