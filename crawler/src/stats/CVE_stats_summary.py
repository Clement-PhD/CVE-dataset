


from dataclasses import asdict, dataclass
import json
import os
from typing import Dict, List, Tuple

from download.warnings import WarningPayload, WarningType


from stats.CVE_stats import CVEStats, Languages


@dataclass
class RepoStatsSummary:
    name: str
    cves_count: int
    languages: set[Languages]
    private_key_files : List[str]

    def to_serializable(self):
        data = asdict(self)
        data['languages'] = [lang.to_serializable() for lang in self.languages]
        return data
    
    @staticmethod
    def from_serializable(data: dict):
        return RepoStatsSummary(
            name=data['name'],
            cves_count=data['cves_count'],
            languages=set([Languages.from_serializable(lang) for lang in data['languages']]),
            private_key_files=data['private_key_files']
        )



@dataclass(frozen = True)
class CVEStatsSummary:
    LANGUAGES_REPO_TO_DISPLAY = [
        Languages.Rust,
        Languages.C,
        Languages.Java,
        Languages.Cpp,
    ]
    # Statistics fields
    total_cves: int
    cves_with_aborted_pull_request: List[Tuple[str, List[str]]]

    total_cves_with_correct_pull_requests: int
    total_cves_with_warnings: int
    total_cves_with_one_modified_file: int

    cves_count_by_language: Dict[Languages, int]
    lines_affected_by_language: Dict[Languages, int]
    files_affected_by_language: Dict[Languages, int]

    repos_to_cve_count: Dict[str, RepoStatsSummary]

    dataset_size: int

    cve_to_files_cant_be_patched: Dict[str, List[WarningPayload]]

    files_extension_stats: Dict[str, int]
    file_number: int

    lines_affected_number: int

    # --------------------- serialization ---------------------

    def to_serializable(self):
        data = asdict(self)
        # Convert the enum to a serializable format
        data['cves_count_by_language'] = {lang.to_serializable(): count for lang, count in self.cves_count_by_language.items()}
        data["lines_affected_by_language"] = {lang.to_serializable(): count for lang, count in self.lines_affected_by_language.items()}
        data["files_affected_by_language"] = {lang.to_serializable(): count for lang, count in self.files_affected_by_language.items()}
        data['repos_to_cve_count'] = {repo: stats.to_serializable() for repo, stats in self.repos_to_cve_count.items()}
        data['cve_to_files_cant_be_patched'] = {cve: [warning.to_serializable() for warning in warnings] for cve, warnings in self.cve_to_files_cant_be_patched.items()}
        return data

    @staticmethod
    def from_serializable(data: dict):
        cves_count_by_language = {Languages.from_serializable(lang): count for lang, count in data['cves_count_by_language'].items()}
        lines_affected_by_language = {Languages.from_serializable(lang): count for lang, count in data['lines_affected_by_language'].items()}
        files_affected_by_language = {Languages.from_serializable(lang): count for lang, count in data['files_affected_by_language'].items()}
        repos_to_cve_count = {repo: RepoStatsSummary.from_serializable(stats) for repo, stats in data['repos_to_cve_count'].items()}
        cve_to_files_cant_be_patched = {cve: [WarningPayload.from_serializable(warning) for warning in warnings] for cve, warnings in data['cve_to_files_cant_be_patched'].items()}
        return CVEStatsSummary(
            total_cves=data['total_cves'],
            cves_with_aborted_pull_request=data['cves_with_aborted_pull_request'],
            total_cves_with_correct_pull_requests=data['total_cves_with_correct_pull_requests'],
            total_cves_with_warnings=data['total_cves_with_warnings'],
            total_cves_with_one_modified_file=data['total_cves_with_one_modified_file'],
            cves_count_by_language=cves_count_by_language,
            lines_affected_by_language=lines_affected_by_language,
            files_affected_by_language=files_affected_by_language,
            repos_to_cve_count=repos_to_cve_count,
            dataset_size=data['dataset_size'],
            cve_to_files_cant_be_patched=cve_to_files_cant_be_patched,
            files_extension_stats=data['files_extension_stats'],
            file_number=data['file_number'],
            lines_affected_number=data['lines_affected_number']
        )

    def save(self, file_path: str):
        data = self.to_serializable()
        with open(file_path, 'w') as f:
            json.dump(data, f, indent=4)
    
    @staticmethod
    def load(file_path: str) -> 'CVEStatsSummary':
        with open(file_path, 'r') as f:
            data = json.load(f)
        return CVEStatsSummary.from_serializable(data)

    # --------------------- creation ---------------------

    @staticmethod
    def create_from_cve_stats(data_folder_path: str, cve_stats: List[CVEStats], cve_not_found_to_urls: List[Tuple[str, List[str]]]) -> 'CVEStatsSummary':
        repo_stats: Dict[str, RepoStatsSummary] = {}
        language_count: Dict[Languages, int] = {}
        lines_affected_by_language: Dict[Languages, int] = {}
        files_affected_by_language: Dict[Languages, int] = {}
        cve_to_files_cant_be_patched: Dict[str, List[WarningPayload]] = {}
        files_extension_stats: Dict[str, int] = {}
        file_number: int = 0

        total_cves_with_warnings = 0
        total_cves_with_one_modified_file = 0
        lines_affected_number = 0

        for cve in cve_stats:
            # Initialize RepoStatsSummary for each repo
            if cve.repo not in repo_stats:
                repo_stats[cve.repo] = RepoStatsSummary(name=cve.repo, cves_count=0, languages=set(), private_key_files=cve.private_key_files)
            repo_stats[cve.repo].cves_count += 1
            repo_stats[cve.repo].private_key_files = list(set(repo_stats[cve.repo].private_key_files + cve.private_key_files))

            if cve.warnings:
                total_cves_with_warnings += 1
                for warning in cve.warnings.warnings:
                    if warning.type == WarningType.CANT_PATCHED:
                        if cve.cve_name not in cve_to_files_cant_be_patched:
                            cve_to_files_cant_be_patched[cve.cve_name] = []
                        cve_to_files_cant_be_patched[cve.cve_name].append(warning)
            if cve.file_number == 1:
                total_cves_with_one_modified_file += 1

            for lang in cve.languages:
                lines_affected_by_language[lang] = lines_affected_by_language.get(lang, 0) + cve.nb_lines_affected
                files_affected_by_language[lang] = files_affected_by_language.get(lang, 0) + cve.file_number
                language_count[lang] = language_count.get(lang, 0) + 1
                repo_stats[cve.repo].languages.add(lang)
            
            for extension, count in cve.files_extension_stats.items():
                files_extension_stats[extension] = files_extension_stats.get(extension, 0) + count
            file_number += cve.file_number
            
            lines_affected_number += cve.nb_lines_affected
            
            

        total_cves_with_correct_pull_requests = len(cve_stats)
        total_cves = total_cves_with_correct_pull_requests + len(cve_not_found_to_urls)

        dataset_size = CVEStatsSummary.__get_folder_size(data_folder_path)

        return CVEStatsSummary(
            total_cves=total_cves,
            cves_with_aborted_pull_request=cve_not_found_to_urls,
            total_cves_with_correct_pull_requests=total_cves_with_correct_pull_requests,
            total_cves_with_warnings=total_cves_with_warnings,
            total_cves_with_one_modified_file=total_cves_with_one_modified_file,
            cves_count_by_language=language_count,
            lines_affected_by_language=lines_affected_by_language,
            files_affected_by_language=files_affected_by_language,
            repos_to_cve_count=repo_stats,
            dataset_size=dataset_size,
            cve_to_files_cant_be_patched=cve_to_files_cant_be_patched,
            files_extension_stats=files_extension_stats,
            file_number=file_number,
            lines_affected_number=lines_affected_number
        )
    


    def print_summary(self, summary_file_path : str | None = None):
        if summary_file_path:
            file = open(summary_file_path, 'w')
        else:
            file = None

        def custom_print(*args, **kwargs):
            print(*args, **kwargs)
            if file:
                print(*args, **kwargs, file=file)

        custom_print("Making stats")
        custom_print(f"Number of CVEs with pull request aborted: {len(self.cves_with_aborted_pull_request)}")
        custom_print(f"Number of CVEs with pull request aborted and one url: {len([cve for cve in self.cves_with_aborted_pull_request if len(cve[1]) == 1])}")

        custom_print("CVEs with pull request aborted:")
        for cve, urls in self.cves_with_aborted_pull_request:
            list_url = ", ".join(urls)
            custom_print(f"\t{cve} : {list_url}")

        custom_print(f"Number of CVEs with correct pull requests: {self.total_cves_with_correct_pull_requests}")
        custom_print(f"Number of CVEs with warnings: {self.total_cves_with_warnings}")
        custom_print(f"Number of CVEs with no warnings: {self.total_cves - self.total_cves_with_warnings}")
        custom_print(f"Number of CVEs with only one modified file: {self.total_cves_with_one_modified_file}")

        custom_print(f"Language statistiques :")
        for language in Languages:
            custom_print(f"\t{language.name} :")
            custom_print(f"\t\tNumber of CVEs : {self.cves_count_by_language.get(language, 0)} ({self.cves_count_by_language.get(language, 0) / self.total_cves * 100:.2f} %)")
            custom_print(f"\t\tNumber of files : {self.files_affected_by_language.get(language, 0)} ({self.files_affected_by_language.get(language, 0) / self.file_number * 100:.2f} %)")
            custom_print(f"\t\tNumber of lines : {self.lines_affected_by_language.get(language, 0)} ({self.lines_affected_by_language.get(language, 0) / self.lines_affected_number * 100:.2f} %)")

        for language in self.LANGUAGES_REPO_TO_DISPLAY:
            custom_print(f"The top 10 repos with the most CVEs (with the language {language}):")
            for repo, summary in sorted([item for item in self.repos_to_cve_count.items() if language in item[1].languages], key=lambda item: item[1].cves_count, reverse=True)[:10]:
                custom_print(f"\t{repo} : {summary.cves_count} ({summary.cves_count / self.total_cves * 100:.2f} %) with the languages: {', '.join([lang.name for lang in summary.languages])}")
            
        custom_print("The top 10 repos with the most CVEs:")
        for repo, summary in sorted(self.repos_to_cve_count.items(), key=lambda item: item[1].cves_count, reverse=True)[:10]:
            custom_print(f"\t{repo} : {summary.cves_count} ({summary.cves_count / self.total_cves * 100:.2f} %) with the languages: {', '.join([lang.name for lang in summary.languages])}")

        custom_print(f"Dataset size: {self.dataset_size / 1024 / 1024 } MB")

        custom_print(f"Number of CVEs with files that can't be patched: {len(self.cve_to_files_cant_be_patched)}")
        for cve, warnings in self.cve_to_files_cant_be_patched.items():
            custom_print(f"\t{cve} : {[warning.file_name for warning in warnings]}")
        
        custom_print(f"Number of files : {self.file_number} for {len(self.files_extension_stats)} extensions and {self.lines_affected_number} lines affected")
        custom_print(f"Number of files by extension (10 best):")
        for extension, count in sorted(self.files_extension_stats.items(), key=lambda item: item[1], reverse=True)[:10]:
            custom_print(f"\t{extension} : {count} ({count / self.file_number * 100:.2f} %)")
        
        repo_with_private_key = [repo for repo, summary in self.repos_to_cve_count.items() if len(summary.private_key_files) > 0]
        custom_print(f"Number of repos with private key: {len(repo_with_private_key)}")
        custom_print(f"Repos with private key:")
        for repo in repo_with_private_key:
            custom_print(f"\t{repo} : {self.repos_to_cve_count[repo].private_key_files}")

        if file:
            file.close()

    @staticmethod
    def __get_folder_size(folder_path : str):
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(folder_path):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                # Skip if it is symbolic link
                if not os.path.islink(fp):
                    total_size += os.path.getsize(fp)
        return total_size